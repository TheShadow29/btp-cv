\documentclass{article}
\usepackage[a4paper, tmargin=1in, bmargin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{pdflscape}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{siunitx}
% \sisetup{round-mode=places,round-precision=2}

\newcommand{\ra}{$\rightarrow$}


\title{Btech Project - Progress Diary}
\author{
  Arka Sadhu}
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\newpage
\section{Daily Progress}
\subsection{Week 1 : July 17 - July 23}
\subsubsection{July 17 : Monday}
Accomplished :
\begin{itemize}
\item Met prof and discussed basic project about deep learning and image co-segmentation.
\item Prof asked to mail and contact sayan banerjee.
\end{itemize}

\subsubsection{July 18 : Tuesday}
Accomplished :
\begin{itemize}
\item Mailed Sayan banerjee, but seems like he has a fever, and also didn't give/suggest any papers unfortunately.
\item Only saw one image cosegmentation paper by Inria, but didn't have the time to read it.
\end{itemize}

\subsubsection{July 19 : Wednesday}
Accomplished :
\begin{itemize}
\item Dowloaded a few papers to read.
\item Init git repository and added basic work report format (from viterbi internship project).
\end{itemize}

\subsubsection{July 20 : Thursday}
Target :
\begin{itemize}
\item Try to meet up with Prof/ Sayan and discuss about possible extensions.
\item Brainstorm ideas as and when time permits.
\item Read as many papers as possible. Complete in-depth reading is not required, simple reading of abstract and reading the relevant papers should be enough.
\end{itemize}

Accomplished :
\begin{itemize}
\item Read the 3 papers :
  \begin{itemize}
  \item Discriminative clustering for image co-segmentation \cite{5539868}: abstract gives basic definition of image co-segmentation as well as says unsupervised segmentation of image into foreground and background regions is still a challenging task. Should be worth reading. Images are also as requried.
  \item Automatic Image Co-segmentation using geometric saliency \cite{7025663}: says co-labelling of multiple images is a complex process, instead suggests segmentation on individual images but based on a saliency map obtained by fusing saliency maps of groups of similar images. Images are also as required. Since it is anyways small, should be worth reading.
  \item Unsupervised 3D shape segementation and co-segmentation via deep learning \cite{SHU201639}: should have been the most related but turns out they do something quite different (at least from first look). They try to automatically segment a single 3D shape or co-segment family of 3D shape. For this they use pre-decompose 3D shape into primitive patches to compute various low level features, then learn high level features in an unsupervised style from low level features based on deep learning, and finally either segmentation or co-segmentation results are fot by patch clustering in high level feature space. The input images are 3D and not 2D as originally required, as such the paper is on Comptuer graphics apparently. But it should be interesting to read the deep learning part of it, i.e. how did they learn the high level features in the unsupervised style from low level features.
  \end{itemize}
\end{itemize}

\subsubsection{July 21 : Friday}
No work done.

\subsubsection{July 22 : Saturday}
No work done

\subsubsection{July 23 : Sunday}
No work done.

\subsubsection{July 24 : Monday}
Meeting with Sayan. Discussion about some basic problems that could be solved. Apparently Video Co-segmentation using Deep learning is not yet looked upon. May be a good breakthrough.

\subsubsection{July 25 : Tuesday}
Target :
\begin{itemize}
\item Read the three papers. \cite{7120111} , \cite{7401081}, \cite{Zhang2014}
\end{itemize}

Accomplished :
\begin{itemize}
\item Able to read only 1 paper properly (not too properly).
\end{itemize}

\subsubsection{July 26 : Wednesday}

\begin{itemize}
\item Couldn't do much. Need to do paper review at the very first.
\item Need to do pytorch tutorials as well.
\item Paper review to be done in a separate file.
\end{itemize}

\subsubsection{July 27 : Thursday}
Accomplished :
\begin{itemize}
\item Completed reading all the papers and joting down main points of the paper.
\item Meeting with Sayan (main points written below):
  \begin{itemize}
  \item Video Co-segmentation hasn't been worked on by the Vision community yet.
  \item The main aim is to make an end-to-end model using RNN.
  \item To circumvent problems of vanishing gradients, we can use LSTM. But for our problem, even LSTM might not suffice.
  \item Hence we can use Memory Augmented LSTM, which should be able to take care of the vanishing gradients.
  \item There is no big datasets for the purpose of Video Co-segmentation. Hence we can look at Weakly unsupervised learning techniques to circumvent this problem.
  \item Need to read 5 papers at the earliest (by Monday). \cite{DBLP:journals/corr/SiamVJR16}, \cite{DBLP:journals/corr/JainZSS15}, \cite{PAVEL2017105}, \cite{DBLP:journals/corr/NohHH15}, \cite{DBLP:journals/corr/GulcehreCB17}
  \end{itemize}
\end{itemize}

\subsubsection{July 28 : Friday}
No work done

\subsubsection{July 29 : Saturday}
Probably no work done

\section{Week 1 : September}
\subsection{Sept 6 : Wednesday}
Discussion with the prof. Main points noted below. Also has what all needs to be done before tomorrow's meeting.
\begin{itemize}
\item Graph Signal. Needs a more concrete definition. Can the vectors be of different dimensions? (I think not, but need to verify this.)
\item An image may have 100-200 superpixels, which is not a constant. So can't use the same graph for all of them. Can we exploit the graph structure? GCN though requires the same graph structure to be followed, otherwise it won't be able to exploit the weights and would essentially require new training and generally useless.
\item We would also like to encode the spatial connections of the superpixels.
\item When we have arbitrary shape, we don't want to have any kind of orientation information, may mess things up.
\item Each superpixel would give some form of a feature vector and we would like to use this feature vector as inputs to the GCN. But need to check if the GCN would actually be of any use?
\item We want to use Graph structure to get some kind of context between the superpixels. So this would be a context sensitive classifier. Need to do extensive literature survey on this.
\item For the case of Co-segmentation the problem is that can we even preserve the graph structure? The nodes? The adjacency graph / matrix. Need to think about these things more carefully.
\item Co-segmentation in general may include both seen/unseen categorization as well. We might need to train on one set of classes and still get outputs on another unseen set of classes. Prof gave the same example as mine, 30C2 combinations, or possibly 25C2 and test on the rest 5C2. We can get the corresponding ground truths as well.
\item Two aspects to the problem of Co-segmentation. Say G1 has m nodes, and G2 has n nodes. We would like to perform subgraph matching problem. What Avik has done is used a greedy algorithm which gives the results quite fast. But I don't think that would be enough actually. Prof suggested to use Graph Neural Networks to solve this problem. This is actually a combinatorial problem. We would like to learn to solve this combinatorial problem.
\item In one case the problem is one-to-one, but here it is possible that it is many-to-many. Because one superpixel may match to two smaller super pixels from the other graph and vice-versa. Solution exists for the one-to-one problem. Sayan's talk tomorrow on the jigsaw puzzle thing is also one-to-one. May need to check the feasibility of such problems.
\item Subgraph Matching Using Deep Learning.
\item The other aspect is the features that are bein given as inputs. Currently it is hog and color features which are in some sense hand-crafted. But what we probably need is more general features. I am thinking in the direction of dilated convolution. May be that can help. [Need to read this one too.]
\item In graphs, the sub-graph matching is NP-complete. To get the MCS : currently greedy algorithm being employed.
\item Another thing to note is that currently we are doing only 0th order. We would like it to be of say some k-ordered, i.e. see till k-hops.
\item So the problem now effectively becomes matching a group of nodes to a group of nodes. A problem that could arise is that number of nodes of the two matching things may not be exactly the same. What we can possibly do is to bring the number of nodes to be the same, by clustering some very similar nodes together.
\end{itemize}

\subsection{Sept 7 : Thursday}
Minutes of the discussion with professor and my answers to the doubts we previously had.
\begin{itemize}
\item First if the graph structure is approximately the same, we can simply do an adjacency approximation and say that the learned parameters are shared across the graphs.
\item Second if the dimensionality of the vectors in each node is different can go to some fixed length representation using attention mechanism.
\item Third is that if the graph is completely different then we can pass on the laplacian as well. My suggestion and partly intuition is that given a graph signal $x_{G1}$ and graph signal $x_{G2}$ belonging to two different graphs, we should be able to find some kind of conversion using the attention mechanism previously described.
\item Then we go to Sayan's Jigsaw puzzle. The problem is formulated in RNN way with LSTM cells.
\item Need to understand how to apply the graph networks to the subgraph matching problems clearly.
\item Also need to understand seq2seq models. One thing I need to know is to how do we manage the problem of having different length vectors in the seq2seq models.
\item Need to read about : Graph Neural Networks as to how they are different from graph convolution networks in what way and all. Second is to read the gated graph attention mechanism given for alleviating different graph structure problem.
\end{itemize}

\bibliography{./papers.bib}
\bibliographystyle{ieeetr}

%\nocite{*}



\end{document}\grid
