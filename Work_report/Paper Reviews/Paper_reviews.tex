\documentclass{article}
\usepackage[a4paper, tmargin=1in, bmargin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{pdflscape}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amssymb}

% \usepackage{siunitx}
% \sisetup{round-mode=places,round-precision=2}

\newcommand{\ra}{$\rightarrow$}


\title{Paper Summaries}
\author{
  Arka Sadhu}
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Unsupervised Co-segmentation for Indefinite Number of Common Foreground Objects}
\cite{7401081}
\subsection{Abstract}
\begin{itemize}
\item Co-segmentation addresses the problem of simultaneously extracting the common targets appeared in Multiple images.
\item Keywords : Co-segmentation, multi-object discovery, adaptive feature, loopy belief propagation
\end{itemize}

\subsection{Introduction}
The paper extends the previous proposal Selection based Co-segmentation[PSCS] methods with the 3 major contributions :
\begin{itemize}
\item Key problem in [PSCS] is mining consistent information shared by the common targets. May require manual selection of features, or feature learning performed beforehand. Here : (simple and effective) self-adaptive feature selection strategy is introduced.
\item Many assume each image contains a single common target and fail for multiple common targets images to extract all targets. Here proposal selection based Unsupervised Co-segmentation [PSUCS] is introduced.
\item For multiple common targets, multi-class co-segmentation approaches do not do so well because of significant appearance variance and the inconsistent number of common targets, also some combinational common trgets are usually splitted into multiple pieces. Here : an adaptive strategy that can handle Indefinite number of common targets involved cases, where each image may contain different number of common targets.
\end{itemize}

\subsection{Problem Formulation}
\begin{itemize}
\item Image set $I = {I_i}, i = {1...M}$, images may contain different number of targets, goal is to extract all common targets.
\item Given $I_i$ generate proposal set $P_i = {p_i^k}, k = {1...K_i}$, set large value for $K$, to make sure that the object proposal set covers all potential common targets.
\item Cos for indefinite number of common targets is transformed into a labeling problem, given $p_i^k$, $x_i^k = 1$ for foreground, else $0$.
\item Union set is viewed as final segmentation result $$R_i = \bigcup \{p_i^k | x_i^k, k \le K_i\}$$
\item Here, the labeling problem in a completely connected network., where each object proposal [OP] is a node, and connected with weighted edges.
\item \underline{Multiple OP of each image is conducted separately}, but closely related to other images of the collection.
\item For each image $I_i$, choose a proposal in every selecting loop to be the real foreground, and in choosing the new loop, we remove the node of the previous proposal to make sure this new proposal would be considered a target, whether this will be chosen as a target depends totally on the labels of other images.
\item \textbf{Therefore}, segmentation problem of image of $I_i$ finally becomes finding an optimal labeling set $x_i = \{x_i^k|k = 1...K_i; x_k \in \{0,1\}\}$ by max the energy function (refer to the paper) : function of weights of the edges and some other constraints.
\item Weight is non-zero and numerically equal to a similarity score between the proposals (to be introduced later). The constraints mean, for each image only one proposal could be selected per loop, and every proposal in image $I_i$ can be selected only once throughout the selection procedure.
\item The formulation is based on the fact that common targets have same characters, and maximizing overall similarity with additional constraint we can make sure newly chosen object proposal is the most similar one to the chosen proposal of the other image. This can be solved via greedy optimization.
\end{itemize}

\subsection{Co-segmentation for Indefinite Number of Common Targets}
Key is to adaptively determining the number of targets, which require fully extracting teh potential targets and then mining the conistent relationships shared by teh common targets.

\subsubsection{Overall Framework}
\begin{enumerate}
\item Category independent OP generated.
\item Connected graph with all proposals as nodes and edge weights as proposal similarities.
\item For reliable similarity, adaptive feature weight selection algorithm.
\item Multiple common targets [MCT] searching, where [MCT] are extracted for each individual image.
\item Terminal condition designed as the common target judging criterion.
\item After termination, simply collect selected proposals.
\end{enumerate}

\subsubsection{Object Proposals Generation}
\begin{enumerate}
\item Very important, directly impacts the performance of Co-segmentation.
\item Measurement of the proposal pool contains mainly two aspects :
  \begin{itemize}
  \item Diversity : cover as many objects as possible.
  \item Representativeness : as few candidates as possible for each object.
  \end{itemize}
\item After a large number of proposals are achieved, a scoring mechanism that combines appearance features and overlap penalty is raised for proposal ranking. There is problem of the proposal containing a local part, but the proposed method could make up for such loss by conducting multiple targets searching.
\end{enumerate}

\subsubsection{Weighted Graph Construction}
\begin{itemize}
\item Usual way : measuring similarity between every two proposals.
\item Choosing fixed features for similarity is not a good option. Adopting a flexible and reliable proposal similarity measurement. Here : Unsupervised self-adaptive similarity measurement is introduced for calculating edge weights. Highly efficient and easy to implement. Example in two images colors might be same, in two other images color might be drastically different.
\item Use iterative weights setting mechanism for the features. Initial proposal labels using loopy belief algo previously, and then iterating to maximize a function.
\item The intuitive intention : encourage selected common targets to be globally consistent while keping a low variance to make the similarity metric more reasonable and representative.
\end{itemize}

\subsubsection{Common Targets Multi-Search Strategy}
Adaptive common target searching strategy that can deal with any numbers of targets.

\begin{itemize}
\item For more common targets , remove previously discovered ones from the candidate pool.
\item Initialize labels $x^{*}$ from prev algo. Basically selecting most likely common targets, by removing the prev most likely common target.
\item Get an adaptive threshold.
\end{itemize}

\section{Video Object Co-segmentation by Regulated Maximum Weight Cliques}
\cite{Zhang2014}

\subsection{Abstract}
\begin{itemize}
\item Novel approach for object co-segmentation in arbitrary videos by sampling, tracking, and matching [OP] via a Regulated Maximum Weight Clique [RMWC] extraction scheme.
\item Achieves good results by pruning away noisy segments in video through selection of [OP] tracklets athat are spatially salient and temporally consistent, and by iteratively extracting weighted groupings of objects with similar shape and appearance (with-in and across videos).
\item Approach is general and handles : multiple objects, temporary occlusions, objects going in and out of view, also doesn't make any prior assumption on the commonality of the objects in the video collection.
\item Keywords : Video Segmentation, Co-segmentation
\end{itemize}

\subsection{Introduction and Related Work}
Goal is to discover and segment objects from a video collection in an unsupervised manner.

\begin{itemize}
\item Video Co-segmentation is natural extension of Image Co-segmentation.
\item In general for video cos, appearance info to group pixels in a spatio-temporal grpah and/or employ motion segmentation techniques to separate objects by using motion cues.
\item Previous work use strong assumptions of single class of object common to all videos.
\item The work has the following advantages :
  \begin{itemize}
  \item Employs object tracklets as opposed to pixel-level or region-level to perform clustering. The eprceptual grouping of pixels before matching reduces segement fragmentation and leads to a simpler matching problem.
  \item No approximate solution. [RMWC] has an optimal solution. Using only object tracklets keeps the computation cost low.
  \item Can handle occlusions, or objects going in and out of the video because the object tracklets are temporally local and there is no requirements for the object to continuously remain in the field of view of the video. Also no limit on teh number of object classes in the each video and number of common object clases in teh video collection. Therefore more general.
  \item Different from [MWC], in that it is regulated by intra-clique consistency term, as a result produces more global consistency.
  \end{itemize}
\end{itemize}

\subsection{Regulated Maximum Weight Clique based Video Co-segmentation}
\subsubsection{Framework}
Two stages :
\begin{enumerate}
\item Object Tracklet Generation : generate [OP] for each frame and use each of them as a starting point and track the object proposals backward and forward trhoughout the whole video seq, and generate reliable tracklets from the track set and perform non-maxima suppression to remove noisy or overlapping proposals.
\item Multiple Objects Co-segmentation by Regulated Maximum Weight Cliques : Tracklets as node, and the nodes are weighted by tracklet similarity, and edges with weight below a threshold are removed. [RMWC] to find objects ranked by score which is a combination of intra-group consistency and Video Object scores.
\end{enumerate}

\subsubsection{Object Tracklets Generation}
\begin{itemize}
\item Generate a number of [OP]. Each proposal has a Video Object Score : combination of motion and appearance. $$S^{object}(x) = A(x) + M(x)$$
\item $A(x)$ : appearance score described directly by algo. High for regions with closed boundary in space, different appearance from its surroundings and is salient.
\item $M(x)$ : motion score defined as the average frob norm of optical flow gradient around the boundary of object proposal.
\item Efficient Object Proposal Tracking :
  \begin{itemize}
  \item Track every object proposal from each frame backward and forwar to form a number of tracks for the object.
  \item Combined color (color histograms to model appearance)+ location(overlap ratio) + shape similarity (contour of region in normalized polar coordinates and sampling it from 0 - 360 deg to form a vector) and then dot product for the first and last.
  \item Greedy tracking : most similar object proposal is selected to be tracked down, computationally requires fnding index of max value in a specific row of the similarity matrix and hence economical.
  \end{itemize}
\item Non-maximum Suppression [NMS] for Object Proposal Tracks :
  \begin{itemize}
  \item Need to prune duplicate (near-duplicate) tracks.
  \item Video Object score for one track is obtained, and see $R_{overlap} > 0.5$ and remove them.
  \item After [NMS] small percentage of total tracks are retained, and to ensure validity of the track associations, remove associations that are 1.5 std from the mean track similarity.
  \end{itemize}
\end{itemize}

\subsubsection{Multiple Object Co-segmentation by [RMWC]}
After object tracklets are obtained, need salient object groupings in the video collection. Grouping problem is formulated as Regulated Maximum Weight Clique.

\begin{itemize}
\item Clique Problems :
  \begin{itemize}
  \item Given G = (V,E,W), a clique is complete subgraph of G, i.e. one whose vertices are pairwise adjacent.
  \item Maximal Clique is a complete subgraph not contained in any other complete subgraph.
  \item Finding all maximal Clique is NP-hard. Maximum Clique problem is to find the  Maximum complete subgraph and Maximum Weight Clique problem deals with finding the Clique with max weight.
  \end{itemize}
\item Problem Constraints :
  \begin{itemize}
  \item Object Proposal Tracklets [OPT] : similar appearance both in video and across video, for in-video L channel used, for across a,b also used.
  \item Shape of same object would not change in the same video, and hence used for building tracklets of same objects in a video.
  \item Dominant object =$>$ high Video Object Score [VOS]
  \item Tracklets generated by an object should have low variation.
  \end{itemize}
\item Graph Structure :
  \begin{itemize}
  \item Object tracklets [OT] are nodes, inter and intra video edges created as described above.
  \item Weak edges removed by a threshold.
  \end{itemize}
\item RMWC :
  \begin{itemize}
  \item Get weight of node.
  \item According to formulation : Clique that has the highest score represents the object with largest combined score of inter-object consistency and objectness. Use NP hard formulation, but doesn't hinder its usage, as number of tracklets are limited, and takes less than a second on standard laptop.
  \end{itemize}
\end{itemize}

\section{Object-Based Multiple Foreground Video Co-Segmentation via Multi-State Selection Graph}
\cite{7120111}
\subsection{Abstract}
\begin{itemize}
\item Multiple foreground Video Co-segmentation for a set of videos.
\item Foreground object in each frame considering intra-video coherence of the fg as well as fg consistency among teh different videos in the set.
\item Multiple foreground handled by multi-state selection graph, node is a video frame, can take multiple labels that correspond to different objects. Also indicator matrix to handle incorrect classification of irrelevant regions.
\item Iterative algo to optimize the function.
\item Index terms : Video Co-segmentation, Multiple Foregrounds, object-based Segmentation
\end{itemize}

\subsection{Introduction}
\begin{itemize}
\item Video foreground Co-segmentation aims at jointly extracting the main common objects present in a given set of videos.
\item Low level may not accurately discriminate fg and bg. Also object based method for single video do not exploit joint info between the videos. Here : handle Multiple fg object in Multiple videos.
\item OP as basic pre-processing. Mid-level features result in more robus and meaningful separation of fg and bg.
\item Graph : nodes is video frames, state : to indicate which object proposal is chosen.
\item Edges between adjacent frames in a video so as to enforce spatio-temporal smoothness of the trajectory of the fg object, while edges beetween frames of different videos are added to emasure foreground consistency.
\item Multi state selection graph [MSG] for multiple states of the nodes to handle multiple Foregrounds. The basic subgraph is replicated multiple times with each replicated subgraph representing a particular foreground object. Can be optimized using existing methods.
\item Relax the condition of existence of the common foreground in all the videos, the method will segment unrelated regions in place of the missing object, and use and indicator matrix to correctly deal with the missing common objects.
\end{itemize}

\subsection{Multi-state selection Graph}
\begin{itemize}
\item Object in a video is a fg if :
  \begin{itemize}
  \item High appearance contrast relative to the bg.
  \item Trajectory of fg object across consecutive video frames is smooth, appearnace and shape are also similar across frames.
  \item In a video fg object appers in each frame.
  \item Additional constraint : on common fg object that they maintain a consistent appearance across different videos.
  \end{itemize}
\item Basic subgraph G = (V, E). Define energy function, $\psi$ for nodes, $\phi$ for edges, and $u_n$ a state taken by each node n in a discrete space. Configuration of states can be done by minimizing the energy function. We seek multiple solutions that are as independent as possible. Introduce a diversity term and define a new optimization problem for MSG.
\item Replicate the basic subgraph K-1 times, to get a total of K, diversity term is incorporated as the edges between teh corresponding nodes in the basic subgraphs, and combined into a unified graph to get a new energy function and it shares the same formulation as the standard graph, so it can be solved directly by existing energy minimization methods to yiedl all of the multiple states at once.
\end{itemize}

\subsection{Object Based Video Co-segmentation}
Suppose V videos, and each video consists of $T_v$ frames. In the MSG, intra-video edges placed between the nodes of adjacent frames, and inter-video edges are fully connected.

\subsubsection{MSG for Video Co-segmentation}
\begin{itemize}
\item MSG selects same number of states for each node, i.e. the object must appear in each frame of each video. Assumption doesn't hold in general. Use indicator matrix $Y \in \mathbb{R}^{V \times K}$, with $y_{vk} = 1$ to denote video v contains object k.
\item Get a new energy function with $y_{vk}$.
\end{itemize}

\subsubsection{Term Definitions}
\begin{itemize}
\item Unary Term :
  \begin{itemize}
  \item $\Psi(.)$ combines three factors (objectness score, motion score, saliency score) for determining the likelihood that an object candidate is the Foreground. Saliency score is considered since the object may not always be moving. Co-saliency is different from saliency : discovers common saliency among multiple images.
  \item Here : compute co-saliency map for each frme and then calculate the mean co-saliency value for each candidate region as the saliency score $S(u)$.
  \end{itemize}
\item Intra Video Term :
  \begin{itemize}
  \item $\Phi_a(., .)$ provides a spatio temporal smoothness constraint between neighboring frames in an individual video.
  \item Uses estimated based on iou with wrapped region w.r.t optical flow mapping.
  \end{itemize}
\item Inter-video Term :
  \begin{itemize}
  \item $\Phi_b(.,.)$ measures Foreground consistency among the videos, considering $\chi^2$ color distances of color histograms and HOG descirptors.
  \end{itemize}
\item Diversity Term :
  \begin{itemize}
  \item $\Delta(.,.)$ to avoid selecting teh same object in different candidate series. Again IOU.
  \end{itemize}
\end{itemize}

\subsubsection{Optimization Procedure}
\begin{itemize}
\item In special cases with fixed indicator matrices $\textbf{Y}$, can be solved directly using existing formulations.
\item If not fixed, develop iterative procedure to approximately update two sets of variables (Y, U) until convergence.
\item Multiple Foreground video Co-segmentation method :
  \begin{itemize}
  \item Initialize Y to all 1
  \item Solve for u.
  \item Update Y. Irrelevant regions have relatively lower unary scores than actual foregrounds. Once $y_{vk}$ updated to 0, can never become 1, to avoid this instead of setting it to 0, set it to $\epsilon (0.0001)$.
  \item Termination : if Y doesn't chage or upon reaching max number of iterations.
  \item Pixel-level Post process : Refine teh selected objects through a pixel-level post-process by usuing a spatiotemporal graph based segmentation method.
  \end{itemize}
\end{itemize}


\bibliography{../Daily_progress/papers.bib}
\bibliographystyle{ieeetr}

%\nocite{*}



\end{document}